<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yoursite.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.13.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="宁静致远">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="宁静致远">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="FanHaiQiang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://yoursite.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>宁静致远</title>
  






  <script async defer data-website-id="" src=""></script>

  <script defer data-domain="" src=""></script>

  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">宁静致远</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">recording & rethinking</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="FanHaiQiang"
      src="/images/my_avatar.gif">
  <p class="site-author-name" itemprop="name">FanHaiQiang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/30/streamis-%E4%BD%9C%E4%B8%9A%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_avatar.gif">
      <meta itemprop="name" content="FanHaiQiang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宁静致远">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 宁静致远">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/30/streamis-%E4%BD%9C%E4%B8%9A%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81/" class="post-title-link" itemprop="url">streamis-作业执行过程源码</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-10-30 12:44:10" itemprop="dateCreated datePublished" datetime="2022-10-30T12:44:10+08:00">2022-10-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-11-05 13:42:13" itemprop="dateModified" datetime="2022-11-05T13:42:13+08:00">2022-11-05</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h2><pre class="mermaid">flowchart TD
构建单次作业 --> 提交创建引擎
提交创建引擎 --> 获取引擎信息
获取引擎信息 --> 更新作业状态</pre>

<ol>
<li><p>构建一次性作业</p>
<p>访问接口<code>/streamis/streamJobManager/job/execute</code>，从数据库中获取 job 信息，封装到<code>StreamisTransformJob</code>实例 中，再经过一系列的转换（<code>Transform</code>）处理（添加 labels、source、作业配置、launchConfig）后得到一个<code>LaunchJob</code>实例。这个实例，会有 linkis 的 <code>SimpleOnceJobBuilder</code> 转成一个 <code>SubmittableSimpleOnceJob</code> 对象，封装了 linkis 客户端和引擎创建 action：<code>CreateEngineConnAction</code>，此外还会将作业要执行的 sql 作为资源上传到 HDFS 便于引擎执行时获取。</p>
</li>
<li><p>提交创建引擎</p>
<p>提交上文创建的 <code>SubmittableSimpleOnceJob</code>，通过 linkis 客户端执行请求<code>CreateEngineConnAction</code>，然后在一个循环中等待引擎就绪，得到一个<code>engineConnId</code>。linkis 启动引擎的过程中，会创建一个<code>FlinkCodeOnceExecutor</code>实例的执行器，这个执行器内部会存储 yarn application id 和 作业所在 node manager 的地址。保存<code>engineConnId</code>和<code>SubmittableSimpleOnceJob</code>实例的映射到缓存<code>onceJobs</code>中。</p>
</li>
<li><p>获取引擎信息</p>
<p>内部创建一个<code>EngineConnOperateAction</code>，通过 linkis 客户端请求，拿到上面的 yarn application id 和 node manger 地址，与 <code>engineConnId</code>、提交用户、ECM 实例 等封装一个 <code>FlinkJobInfo</code> 实例中。保存<code>engineConnId</code>和<code>FlinkJobInfo</code>实例的映射到缓存<code>onceJobIdToJobInfo</code>中。</p>
</li>
<li><p>更新作业状态</p>
<p>类<code>TaskMonitorService</code> 中有个定时任务，从数据库中获取未完成的任务，根据任务的 <code>engineConnId</code>从映射中拿到<code>SubmittableSimpleOnceJob</code>实例，内部会创建一个<code>GetEngineConnAction</code>，有 linkis 客户端发起请求，获取节点信息，里面包含了引擎的状态。</p>
</li>
</ol>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2022/10/30/streamis-%E4%BD%9C%E4%B8%9A%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/30/flinkx-1-11-%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%BF%9C%E7%A8%8B-jar-%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E5%A4%84%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_avatar.gif">
      <meta itemprop="name" content="FanHaiQiang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宁静致远">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 宁静致远">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/30/flinkx-1-11-%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%BF%9C%E7%A8%8B-jar-%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E5%A4%84%E7%90%86/" class="post-title-link" itemprop="url">flinkx 1.11 中使用远程 jar 遇到的问题与处理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-10-30 12:16:59 / 修改时间：12:17:49" itemprop="dateCreated datePublished" datetime="2022-10-30T12:16:59+08:00">2022-10-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>随着任务不断迁移，datahub api 需要提交的任务也越来越多，带来的问题包括但不限于如下</p>
<ol>
<li>客户端压力大，导致作业提交失败，之前发生过提交子进程内存耗尽</li>
<li>大量任务同时上传文件到 HDFS，导致上传变慢，失败后重试，甚至上传失败</li>
</ol>
<p>之前优化了 jar 重复上传的问题，上周例会上龙哥也做了一件类似的事，将 flink lib 的目录下的 jar 上传到 hdfs，任务使用远程 jar ，这样可以省去本地上传的过程。由于 flinkx 作业几乎不会改动到 flink 的 jar 包，使用远程 jar 可以节省至少一半上传数据量。<br>接下来记录下验证过程中碰到的一个问题<br>虽然配置了远程的 jar 但是要把本地的 lib 目录清空了才不会上传。但是清空之后有个问题，任务启动失败报错有个类找不到。挨个尝试，最终发现要在本地 lib 目录中，保留以 Hadoop shaded jar 才行。<br><img src="/2022/10/30/flinkx-1-11-%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%BF%9C%E7%A8%8B-jar-%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E5%A4%84%E7%90%86/image_1666956868228_0.png" alt="image.png"><br>之所以会上传是因为 flinkx 在创建 yarndescriptor 时候，将 flink lib 目录中的 jar 添加到 ship files 中了，在执行 start app master 这个方法的时候 会把 ship files 中的文件上传。<br>后面发现添加配置项 <code>yarn.per-job-cluster.include-user-jar : FIRST</code> 后任务可以执行了，带来的变化是<br><img src="/2022/10/30/flinkx-1-11-%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%BF%9C%E7%A8%8B-jar-%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%B8%8E%E5%A4%84%E7%90%86/image_1666956956724_0.png" alt="image.png"><br>但是这里有个问题，按类路径里的顺序 往后不是也能从 flinkx-release_1.11.0.jar 这个包里找到需要的类么？<br>第二天过来，按照类加载的顺序，看了这两个 jar ：<code>flinkx-hdfs-writer-release_1.11.0.jar</code> 和 <code>flinkx-release_1.11.0.jar</code>，发现问题了</p>
<ol>
<li>不设置 FIRST ，会从 <code>flinkx-hdfs-writer-release_1.11.0.jar</code> 这个 jar 中加载到类，<code>org.apache.commons.cli.Option</code>。 这个类是 commons-cli 1.2 版本的，它的实现中没有 builder 这个方法。</li>
<li>设置了 FIRST，会从 <code>flinkx-release_1.11.0.jar</code> 这个 jar 中加载 Option 类。这个 jar 中的 commons-cli 是 1.3.1 版本的，是有这个方法的。</li>
</ol>
<p>之前为什么会 “挨个尝试，最终发现要在本地 lib 目录中，保留 flink-shaded-hadoop-2-uber-2.6.5-10.0.jar 这个 jar” 也是这个原因，这个 jar 里面的 Option 类是对的。本地 lib 中 jar 会出现在 classpath 的前面，如下，所以会加载到正确的类。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/30/flinkx-1-7-jar-%E4%B8%8A%E4%BC%A0%E9%80%BB%E8%BE%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_avatar.gif">
      <meta itemprop="name" content="FanHaiQiang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宁静致远">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 宁静致远">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/30/flinkx-1-7-jar-%E4%B8%8A%E4%BC%A0%E9%80%BB%E8%BE%91/" class="post-title-link" itemprop="url">flinkx 1.7 jar 上传逻辑</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-10-30 12:11:11 / 修改时间：12:15:41" itemprop="dateCreated datePublished" datetime="2022-10-30T12:11:11+08:00">2022-10-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>flinkx 1.7 任务启动过程中要上传的 jar 分两部分</p>
<ol>
<li>flink lib 目录下的 jar，又细分成两部分 flink-dist 和 非 flink-dist，以及<del>具体的 flinkx 插件 jar 包</del></li>
<li>flinkx 插件目录下的 jar，又细分成 flinkx.jar （对应 flinkx-core 模块）和具体插件的 jar</li>
</ol>
<p>在具体的上传过程中，<br>flink-dist 单独上传</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Path</span> <span class="variable">remotePathJar</span> <span class="operator">=</span> setupSingleLocalResource(</span><br><span class="line">  <span class="string">&quot;flink.jar&quot;</span>,</span><br><span class="line">  fs,</span><br><span class="line">  appId,</span><br><span class="line">  flinkJarPath,</span><br><span class="line">  localResources,</span><br><span class="line">  homeDir,</span><br><span class="line">  <span class="string">&quot;&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>其他的 jar 作业 user jar 一起上传</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (jobGraph != <span class="literal">null</span>) &#123;</span><br><span class="line">  <span class="comment">// add the user code jars from the provided JobGraph</span></span><br><span class="line">  <span class="comment">// 这里所说的 user code jars 就是 flinkx plugin 目录下的 flinkx.jar</span></span><br><span class="line">  <span class="keyword">for</span> (org.apache.flink.core.fs.Path path : jobGraph.getUserJars()) &#123;</span><br><span class="line">    userJarFiles.add(<span class="keyword">new</span> <span class="title class_">File</span>(path.toUri()));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (userJarInclusion != YarnConfigOptions.UserJarInclusion.DISABLED) &#123;</span><br><span class="line">  userClassPaths = uploadAndRegisterFiles(</span><br><span class="line">    userJarFiles,</span><br><span class="line">    fs,</span><br><span class="line">    homeDir,</span><br><span class="line">    appId,</span><br><span class="line">    paths,</span><br><span class="line">    localResources,</span><br><span class="line">    envShipFileList);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  userClassPaths = Collections.emptyList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>userJarFiles</code> 的初始化是在<code>com.dtstack.flinkx.launcher.perjob.PerJobClusterClientBuilder#createPerJobClusterDescriptor</code>，这里将 flink lib 目录下除 flink-dist jar 之外的所有 jar 放到了 <code>userJarFiles</code> 中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">List&lt;URL&gt; classpaths = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"><span class="keyword">if</span> (flinkJarPath != <span class="literal">null</span>) &#123;</span><br><span class="line">  File[] jars = <span class="keyword">new</span> <span class="title class_">File</span>(flinkJarPath).listFiles();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (File file : jars)&#123;</span><br><span class="line">    <span class="keyword">if</span> (file.toURI().toURL().toString().contains(<span class="string">&quot;flink-dist&quot;</span>))&#123;</span><br><span class="line">      clusterDescriptor.setLocalJarPath(<span class="keyword">new</span> <span class="title class_">Path</span>(file.toURI().toURL().toString()));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      classpaths.add(file.toURI().toURL());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;The Flink jar path is null&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">clusterDescriptor.setProvidedUserJarFiles(classpaths);</span><br></pre></td></tr></table></figure>

<p>这个过程中存在问题是，所有的插件 jar 在 flink lib 目录下都存在了一份，提交的作业时不管有没有使用到都会上传。</p>
<p>理想的状态是，任务使用了哪些插件，就上传这些插件对应的 jar。</p>
<p>任务使用了哪些插件，可以从任务配置文件中解析得到。这个解析过程，在<code>com.dtstack.flinkx.launcher.Launcher#analyzeUserClasspath</code>方法中已经完成，保存在<code>clusterSpecification.classpaths</code> 中。并且在后续获取 <code>PackagedProgram</code> 和 <code>JobGraph</code> 对象时，又保存到了各自对象的 <code>classpaths</code> 变量中。</p>
<p>一个处理的方法是：</p>
<ol>
<li>将插件包从 flink lib 目录下删除</li>
<li>上面上传 <code>userJarFiles</code> 表示的 jar 包之前，从 <code>jobGraph</code> 中获取了 <code>flinkx.jar</code>，可以做一个类似的操作，即：将 <code>jobGraph.classpath</code> 中的 jar （就是任务需要的插件包）一并添加到 <code>userJarFiles</code> 中，待后续上传。</li>
<li>还有个方法，同事给出的，是在 <code>com.dtstack.flinkx.launcher.perjob.PerJobClusterClientBuilder#createPerJobClusterDescriptor</code>方法中设置 classpaths 时，从 clusterSpefication 中获取解析出的插件包添加到 classpaths 中。</li>
</ol>
<p>如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">List&lt;URL&gt; classpaths = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">clusterSpecification.getClasspaths().forEach(jar-&gt;classpaths.add(jar));</span><br><span class="line"><span class="keyword">if</span> (flinkJarPath != <span class="literal">null</span>) &#123;</span><br><span class="line">  File[] jars = <span class="keyword">new</span> <span class="title class_">File</span>(flinkJarPath).listFiles();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (File file : jars)&#123;</span><br><span class="line">    <span class="keyword">if</span> (file.toURI().toURL().toString().contains(<span class="string">&quot;flink-dist&quot;</span>))&#123;</span><br><span class="line">      clusterDescriptor.setLocalJarPath(<span class="keyword">new</span> <span class="title class_">Path</span>(file.toURI().toURL().toString()));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      classpaths.add(file.toURI().toURL());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;The Flink jar path is null&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">clusterDescriptor.setProvidedUserJarFiles(classpaths);</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/30/mongo-%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%E6%88%90%E5%8A%9F%E4%BD%86%E6%95%B0%E6%8D%AE%E9%87%8F%E4%B8%8D%E5%AF%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_avatar.gif">
      <meta itemprop="name" content="FanHaiQiang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宁静致远">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 宁静致远">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/30/mongo-%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%E6%88%90%E5%8A%9F%E4%BD%86%E6%95%B0%E6%8D%AE%E9%87%8F%E4%B8%8D%E5%AF%B9/" class="post-title-link" itemprop="url">mongo 任务执行成功但数据量不对</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-10-30 12:05:53 / 修改时间：12:06:49" itemprop="dateCreated datePublished" datetime="2022-10-30T12:05:53+08:00">2022-10-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>业务反馈了一个同步 hive 数据到 mongo 的作业，同步结束后，mongo 里面的数据量与 hive 的对不上，任务运行日志中有 118 条记录写失败了。<br>初看这个任务有一点奇怪：flinkx 中有一个数据量的检测机制，如果写失败了，错误记录数或者错误记录比例超过一定阈值，作业就失败了。这个作业有记录写失败了，为什么还是成功的呢？带着这个疑惑，重新看了下错误检测机制，分为两个部分：初始化和校验</p>
<p>在<code>com.dtstack.flinkx.outputformat.BaseRichOutputFormat#open</code> 内部会调用方法<code>com.dtstack.flinkx.outputformat.BaseRichOutputFormat#initStatisticsAccumulator</code>初始化累加器（比如错误记录数 <code>errCounter</code>），具体是通过 flink runtime 创建计数器，并将这些计数器添加到指标组中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">initStatisticsAccumulator</span><span class="params">()</span>&#123;</span><br><span class="line">  errCounter = context.getLongCounter(Metrics.NUM_ERRORS);</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  outputMetric = <span class="keyword">new</span> <span class="title class_">BaseMetric</span>(context);</span><br><span class="line">  outputMetric.addMetric(Metrics.NUM_ERRORS, errCounter);</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  startTime = System.currentTimeMillis();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后调用方法<code>com.dtstack.flinkx.outputformat.BaseRichOutputFormat#initAccumulatorCollector</code>初始话计数器收集器<code>accumulatorCollector</code>，内部会启动一个定时任务，执行方法<code>com.dtstack.flinkx.metrics.AccumulatorCollector#collectAccumulatorWithApi</code>从 JM 获取计数器的值。<br>校验过程有两处：每一行数据写之前；以及所有数据写完。<br>写之前是在方法<code>com.dtstack.flinkx.outputformat.BaseRichOutputFormat#writeSingleRecord</code>中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">writeSingleRecord</span><span class="params">(Row row)</span> &#123;</span><br><span class="line">  <span class="keyword">if</span>(errorLimiter != <span class="literal">null</span>) &#123;</span><br><span class="line">    errorLimiter.acquire();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    writeSingleRecordInternal(row);</span><br><span class="line">  &#125; </span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里先调用方法<code>com.dtstack.flinkx.writer.ErrorLimiter#acquire</code>获取错误的情况，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">String</span> <span class="variable">errorDataStr</span> <span class="operator">=</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">  <span class="keyword">if</span>(errorData != <span class="literal">null</span>)&#123;</span><br><span class="line">    errorDataStr = errorData.toString() + <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">long</span> <span class="variable">errors</span> <span class="operator">=</span> accumulatorCollector.getAccumulatorValue(Metrics.NUM_ERRORS);</span><br><span class="line">  <span class="keyword">if</span>(maxErrors != <span class="literal">null</span> &amp;&amp; !maxErrors.equals(<span class="number">0</span>))&#123;</span><br><span class="line">    Preconditions.checkArgument(errors &lt;= maxErrors, <span class="string">&quot;WritingRecordError: error writing record [&quot;</span> + errors + <span class="string">&quot;] exceed limit [&quot;</span> + maxErrors</span><br><span class="line">                                + <span class="string">&quot;]\n&quot;</span> + errorDataStr + errMsg);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(maxErrorRatio != <span class="literal">null</span>)&#123;</span><br><span class="line">    <span class="type">long</span> <span class="variable">numRead</span> <span class="operator">=</span> accumulatorCollector.getAccumulatorValue(Metrics.NUM_READS);</span><br><span class="line">    <span class="keyword">if</span>(numRead &gt;= <span class="number">1</span>) &#123;</span><br><span class="line">      errorRatio = (<span class="type">double</span>) errors / numRead;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Preconditions.checkArgument(errorRatio &lt;= maxErrorRatio, <span class="string">&quot;WritingRecordError: error writing record ratio [&quot;</span> + errorRatio + <span class="string">&quot;] exceed limit [&quot;</span> + maxErrorRatio</span><br><span class="line">                                + <span class="string">&quot;]\n&quot;</span> + errorDataStr + errMsg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从计数器收集器<code>accumulatorCollector</code>中获取错误数<code>errors</code>和错误比例（错误数&#x2F;读取数）<code>errorRatio = (**double**) errors / numRead</code>。如果超过最大错误数<code>maxErrors</code>或者最大错误比例<code>maxErrorRatio</code>，抛出异常。<br>由于上面的检测是在写之前，对于最后一次写，还是有可能失败的，所以写完之后，又有一次检测，也是调用方法<code>com.dtstack.flinkx.writer.ErrorLimiter#acquire</code>。具体是在方法<code>com.dtstack.flinkx.outputformat.BaseRichOutputFormat#checkErrorLimit</code>中，由<code>com.dtstack.flinkx.outputformat.BaseRichOutputFormat#close</code>方法调用。<br>至此，错误检测机制说明白了。那为什么没有生效呢？可能的原因就是检测条件不成立，即<code>maxErrors</code>为 null 或者 0；<code>maxErrorRatio</code> 为 null。顺着这个思路找到这两个值初始化的源头，<code>com.dtstack.flinkx.mongodb.writer.MongodbWriter#writeData</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> DataStreamSink&lt;?&gt; writeData(List&lt;DataStream&lt;Row&gt;&gt; dataSets) &#123;</span><br><span class="line">  <span class="type">MongodbOutputFormatBuilder</span> <span class="variable">builder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MongodbOutputFormatBuilder</span>();</span><br><span class="line"></span><br><span class="line">  builder.setMongodbConfig(mongodbConfig);</span><br><span class="line">  builder.setColumns(columns);</span><br><span class="line">  builder.setMonitorUrls(monitorUrls);</span><br><span class="line">  builder.setErrors(errors);</span><br><span class="line">  builder.setDirtyPath(dirtyPath);</span><br><span class="line">  builder.setDirtyHadoopConfig(dirtyHadoopConfig);</span><br><span class="line">  builder.setSrcCols(srcCols);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> createOutput(dataSets, builder.finish());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看到这里处理了 <code>errors</code>，没有处理<code>errorRatio</code>。而<code>errors</code>是从南天门给的配置中获取的，取值为 0。如此两个检测条件都不成立，所以任务没有失败。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;errorLimit&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span> <span class="number">0.01</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;record&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/30/%E8%BF%9E%E4%B8%8D%E4%B8%8A-HS2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_avatar.gif">
      <meta itemprop="name" content="FanHaiQiang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宁静致远">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 宁静致远">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/30/%E8%BF%9E%E4%B8%8D%E4%B8%8A-HS2/" class="post-title-link" itemprop="url">连不上 HS2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-10-30 11:43:37 / 修改时间：11:49:46" itemprop="dateCreated datePublished" datetime="2022-10-30T11:43:37+08:00">2022-10-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>作业执行失败报错如下  </p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tried <span class="attribute">all</span> existing HiveServer2 uris <span class="selector-tag">from</span> ZooKeeper.</span><br></pre></td></tr></table></figure>

<p>目前 HS2 通过 ZK 做了 HA，从报错日志看，将 ZK 里面配置的 HS2 依次连接了一遍，都失败了。过往的经验是有两个可能的问题</p>
<p>jdbc 连接串（ <code>jdbc:hive2://10.1.183.246,10.1.178.113,10.1.166.18:2181/usercenter;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=sgp -com-hive;hive.server2.proxy.user=sg_ib_dw?mapred.job.queue.name=root.ib.sgoffline</code> ）有问题<br>HS2 地址中使用的是主机名，从主机名解析获取 IP 地址失败</p>
<p>第一个问题通过 beeline 连接给定的 jdbc 连接串验证，可以连上，说明不是这个问题；  </p>
<p>第二个问题可以从 ZK 中获取 HS2 地址，通过 ping 或者 telnet 命令验证，验证通过，说明也不是这个问题  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取 HS2 地址</span></span><br><span class="line">[zk: 10.1.166.18:2181(CONNECTED) 0] ls /sgp-com-hive</span><br><span class="line">[serverUri=10-94-12-217.sgp-com-hiveserver2.sgp:10000;version=2.3.7-amzn-1;sequence=0000001812, serverUri=10-94-104-44.sgp-com-hiveserver2.sgp:10000;version=2.3.7-amzn-1;sequence=0000001795, serverUri=10-94-106-212.sgp-com-hiveserver2.sgp:10000;version=2.3.7-amzn-1;sequence=0000001771]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">telnet 验证</span></span><br><span class="line">[service@10-94-48-163.datahub-api.sgp lib]$ telnet 10-94-12-217.sgp-com-hiveserver2.sgp 10000</span><br><span class="line">Trying 10.94.12.217...</span><br><span class="line">Connected to 10-94-12-217.sgp-com-hiveserver2.sgp.</span><br><span class="line">Escape character is &#x27;^]&#x27;.</span><br><span class="line">^]</span><br><span class="line"><span class="meta prompt_">telnet&gt; </span><span class="language-bash">quit</span></span><br><span class="line">Connection closed.</span><br></pre></td></tr></table></figure>

<p>接下来，看下 hive jdbc 是如何创建连接的，从异常栈中是看到相关的类是  <code>org.apache.hive.jdbc.HiveConnection#HiveConnection</code> ，之前在hive-读取超时中有描述 jdbc 打开 hive 连接的大致流程，接下来看下其中遍历 ZK 中配置的 HS2，依次尝试连接，直到成功或者失败的过程。  </p>
<p>从方法 <code>org.apache.hive.jdbc.Utils#parseURL</code> 开始解析 jdbc url 连接， <code>jdbc:hive2://&lt;host1&gt;:&lt;port1&gt;,&lt;host2&gt;:&lt;port2&gt;/dbName;sess_var_list?hive_conf_list#hive_var_list</code> ，其中几个 list 是以 <code>;</code> 分隔的键值对，分别对应 URI 的 path、query和fragment，内部也是用 URI 类来提取的各个部分的。最后会调用 <code>org.apache.hive.jdbc.Utils#configureConnParams</code>  处理 <code>connParams</code> ，从 ZK 中获取真实的主机和端口，并替换 <code>dummyAuthorityString</code> 。  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> JdbcConnectionParams <span class="title function_">parseURL</span><span class="params">(String uri)</span> <span class="keyword">throws</span> JdbcUriParseException,</span><br><span class="line">SQLException, ZooKeeperHiveClientException &#123;</span><br><span class="line">  <span class="type">JdbcConnectionParams</span> <span class="variable">connParams</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JdbcConnectionParams</span>();</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="comment">// Extract host, port</span></span><br><span class="line">  <span class="keyword">if</span> (connParams.isEmbeddedMode()) &#123;</span><br><span class="line">    <span class="comment">// In case of embedded mode we were supplied with an empty authority.</span></span><br><span class="line">    <span class="comment">// So we never substituted the authority with a dummy one.</span></span><br><span class="line">    connParams.setHost(jdbcURI.getHost());</span><br><span class="line">    connParams.setPort(jdbcURI.getPort());</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Configure host, port and params from ZooKeeper if used,</span></span><br><span class="line">    <span class="comment">// and substitute the dummy authority with a resolved one</span></span><br><span class="line">    configureConnParams(connParams); <span class="comment">//就是这里</span></span><br><span class="line">    <span class="comment">// We check for invalid host, port while configuring connParams with configureConnParams()</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">authorityStr</span> <span class="operator">=</span> connParams.getHost() + <span class="string">&quot;:&quot;</span> + connParams.getPort();</span><br><span class="line">    LOG.info(<span class="string">&quot;Resolved authority: &quot;</span> + authorityStr);</span><br><span class="line">    uri = uri.replace(dummyAuthorityString, authorityStr);</span><br><span class="line">    connParams.setJdbcUriString(uri);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> connParams;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>方法 <code>org.apache.hive.jdbc.Utils#configureConnParams</code> 内部会判断服务发现模式是不是 <code>zooKeeper</code> （在 jdbc url 的 session var 中有给出，即： <code>serviceDiscoveryMode=zooKeeper;</code> ），执行 <code>org.apache.hive.jdbc.ZooKeeperHiveClientHelper#configureConnParams</code> 从 ZK 获取配置  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">configureConnParams</span><span class="params">(JdbcConnectionParams connParams)</span></span><br><span class="line">  <span class="keyword">throws</span> JdbcUriParseException, ZooKeeperHiveClientException &#123;</span><br><span class="line">  <span class="type">String</span> <span class="variable">serviceDiscoveryMode</span> <span class="operator">=</span></span><br><span class="line">    connParams.getSessionVars().get(JdbcConnectionParams.SERVICE_DISCOVERY_MODE);</span><br><span class="line">  <span class="keyword">if</span> ((serviceDiscoveryMode != <span class="literal">null</span>)</span><br><span class="line">      &amp;&amp; (JdbcConnectionParams.SERVICE_DISCOVERY_MODE_ZOOKEEPER</span><br><span class="line">          .equalsIgnoreCase(serviceDiscoveryMode))) &#123;</span><br><span class="line">    <span class="comment">// Set ZooKeeper ensemble in connParams for later use</span></span><br><span class="line">    connParams.setZooKeeperEnsemble(joinStringArray(connParams.getAuthorityList(), <span class="string">&quot;,&quot;</span>));</span><br><span class="line">    <span class="comment">// Configure using ZooKeeper</span></span><br><span class="line">    ZooKeeperHiveClientHelper.configureConnParams(connParams);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>看方法 <code>org.apache.hive.jdbc.ZooKeeperHiveClientHelper#configureConnParams</code> 内部实现<br>从指定空间（在 jdbc url 的 session var 中指定：即 <code>zooKeeperNamespace=sgp-com-hive</code> ）中获取 HS2 列表 <code>serverHosts</code><br>将 <code>serverHosts</code> 中已经尝试连接过的 HS2 剔除掉（连接失败的 HS2 会记录到^^拒绝连接列表^^中，下文中有描述）<br>如果没有可用的 HS2，就抛出前面任务失败的异常 <code>Tried all existing HiveServer2 uris from ZooKeeper.</code><br>从可用的 HS2 随机选择一个，获取对应 znode 内容  <code>serverConfStr</code> ，即对应 HS2 的配置：</p>
<figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[zk: 10.1.166.18:2181(CONNECTED) 0] ls /sgp-com-hive</span><br><span class="line">[serverUri=10<span class="string">-94</span><span class="string">-12</span><span class="string">-217</span>.sgp-com-hiveserver2.sgp:10000;version=2.3.7-amzn<span class="string">-1</span>;sequence=0000001812, serverUri=10<span class="string">-94</span><span class="string">-104</span><span class="string">-44</span>.sgp-com-hiveserver2.sgp:10000;version=2.3.7-amzn<span class="string">-1</span>;sequence=0000001795, serverUri=10<span class="string">-94</span><span class="string">-106</span><span class="string">-212</span>.sgp-com-hiveserver2.sgp:10000;version=2.3.7-amzn<span class="string">-1</span>;sequence=0000001771]</span><br><span class="line">[zk: 10.1.166.18:2181(CONNECTED) 1] get /sgp-com-hive/serverUri=10<span class="string">-94</span><span class="string">-12</span><span class="string">-217</span>.sgp-com-hiveserver2.sgp:10000;version=2.3.7-amzn<span class="string">-1</span>;sequence=0000001812</span><br><span class="line">hive.server2.authentication=CUSTOM;hive.server2.transport.mode=binary;hive.server2.thrift.sasl.qop=auth;hive.server2.thrift.bind.host=10<span class="string">-94</span><span class="string">-12</span><span class="string">-217</span>.sgp-com-hiveserver2.sgp;hive.server2.thrift.port=10000;hive.server2.use.SSL=false</span><br></pre></td></tr></table></figure>

<p>重新整理后如下  </p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hive.server2.authentication</span>=CUSTOM<span class="comment">;</span></span><br><span class="line"><span class="attr">hive.server2.transport.mode</span>=binary<span class="comment">;</span></span><br><span class="line"><span class="attr">hive.server2.thrift.sasl.qop</span>=auth<span class="comment">;</span></span><br><span class="line"><span class="attr">hive.server2.thrift.bind.host</span>=<span class="number">10</span>-<span class="number">94</span>-<span class="number">12</span>-<span class="number">217</span>.sgp-com-hiveserver2.sgp<span class="comment">;</span></span><br><span class="line"><span class="attr">hive.server2.thrift.port</span>=<span class="number">10000</span><span class="comment">;</span></span><br><span class="line"><span class="attr">hive.server2.use.SSL</span>=<span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>调用方法 <code>applyConfs</code>  应用配置 <code>serverConfStr</code> ，即将上面的配置依次设置到 <code>connParams</code> 中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">configureConnParams</span><span class="params">(JdbcConnectionParams connParams)</span></span><br><span class="line">  <span class="keyword">throws</span> ZooKeeperHiveClientException &#123;</span><br><span class="line">  <span class="comment">//省略...</span></span><br><span class="line">  serverHosts = zooKeeperClient.getChildren().forPath(<span class="string">&quot;/&quot;</span> + zooKeeperNamespace);</span><br><span class="line">  <span class="comment">// Remove the znodes we&#x27;ve already tried from this list</span></span><br><span class="line">  serverHosts.removeAll(connParams.getRejectedHostZnodePaths());</span><br><span class="line">  <span class="keyword">if</span> (serverHosts.isEmpty()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">ZooKeeperHiveClientException</span>(</span><br><span class="line">      <span class="string">&quot;Tried all existing HiveServer2 uris from ZooKeeper.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Now pick a server node randomly</span></span><br><span class="line">  serverNode = serverHosts.get(randomizer.nextInt(serverHosts.size()));</span><br><span class="line">  connParams.setCurrentHostZnodePath(serverNode);</span><br><span class="line">  <span class="comment">// Read config string from the znode for this server node</span></span><br><span class="line">  <span class="type">String</span> <span class="variable">serverConfStr</span> <span class="operator">=</span></span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">String</span>(</span><br><span class="line">    zooKeeperClient.getData().forPath(<span class="string">&quot;/&quot;</span> + zooKeeperNamespace + <span class="string">&quot;/&quot;</span> + serverNode),</span><br><span class="line">    Charset.forName(<span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line">  applyConfs(serverConfStr, connParams);</span><br><span class="line">  <span class="comment">//省略 ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>支持连接参数 <code>connParams</code> 初始化完成，接下来调用方法 <code>org.apache.hive.jdbc.HiveConnection#openTransport</code> 打开与 ThriftServer 的连接，在一个 while true 的循环中尝试连接，处理异常。看下其中处理打开异常的部分：   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">openTransport</span><span class="params">()</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      transport = isHttpTransportMode() ? createHttpTransport() : createBinaryTransport();</span><br><span class="line">      <span class="keyword">if</span> (!transport.isOpen()) &#123;</span><br><span class="line">        transport.open();</span><br><span class="line">      &#125;</span><br><span class="line">      logZkDiscoveryMessage(<span class="string">&quot;Connected to &quot;</span> + connParams.getHost() + <span class="string">&quot;:&quot;</span> + connParams.getPort());</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (TTransportException e) &#123;</span><br><span class="line">      <span class="comment">// We&#x27;ll retry till we exhaust all HiveServer2 nodes from ZooKeeper</span></span><br><span class="line">      <span class="keyword">if</span> (isZkDynamicDiscoveryMode()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          Utils.updateConnParamsFromZooKeeper(connParams); <span class="comment">//这里</span></span><br><span class="line">          <span class="comment">//...</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>在通过 ZK 做动态发现模式下（方法 <code>isZkDynamicDiscoveryMode()</code> ）,调用方法 <code>org.apache.hive.jdbc.Utils#updateConnParamsFromZooKeeper</code> 重新获取一个 HS2<br>首先，将当前尝试连接的节点节点添加到^^拒绝节点列表^^中<br>暂存当前使用 HS2 的 host 和 port<br>调用前面介绍的方法 <code>org.apache.hive.jdbc.ZooKeeperHiveClientHelper#configureConnParams</code> 重新获取一个 HS2<br>使用新获取的 HS2 的 host 和 port 替换旧的 </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">updateConnParamsFromZooKeeper</span><span class="params">(JdbcConnectionParams connParams)</span></span><br><span class="line">  <span class="keyword">throws</span> ZooKeeperHiveClientException &#123;</span><br><span class="line">  <span class="comment">// Add current host to the rejected list</span></span><br><span class="line">  connParams.getRejectedHostZnodePaths().add(connParams.getCurrentHostZnodePath());</span><br><span class="line">  <span class="type">String</span> <span class="variable">oldServerHost</span> <span class="operator">=</span> connParams.getHost();</span><br><span class="line">  <span class="type">int</span> <span class="variable">oldServerPort</span> <span class="operator">=</span> connParams.getPort();</span><br><span class="line">  <span class="comment">// Update connection params (including host, port) from ZooKeeper</span></span><br><span class="line">  ZooKeeperHiveClientHelper.configureConnParams(connParams);</span><br><span class="line">  connParams.setJdbcUriString(connParams.getJdbcUriString().replace(</span><br><span class="line">    oldServerHost + <span class="string">&quot;:&quot;</span> + oldServerPort, connParams.getHost() + <span class="string">&quot;:&quot;</span> + connParams.getPort()));</span><br><span class="line">  LOG.info(<span class="string">&quot;Selected HiveServer2 instance with uri: &quot;</span> + connParams.getJdbcUriString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>至此，通过 ZK 来实现 HS2 高可用的流程就结束了。  </p>
<p>看来问题还是在连接 HS2 出现了异常，即 <code>transport.open();</code> 这里，内部的代码没有细看，大致用了 SASL 做认证，其中会从  <code>sessConfMap</code>  中获取用户和密码，会不会是认证出现了问题了？  </p>
<p>用户名和密码是在创建对象 <code>HiveConnection</code> 是，从传入变量 <code>info</code> 中拿到后设置到 <code>sessConfMap</code> 中的  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (info.containsKey(JdbcConnectionParams.AUTH_USER)) &#123;</span><br><span class="line">  sessConfMap.put(JdbcConnectionParams.AUTH_USER, info.getProperty(JdbcConnectionParams.AUTH_USER));</span><br><span class="line">  <span class="keyword">if</span> (info.containsKey(JdbcConnectionParams.AUTH_PASSWD)) &#123;</span><br><span class="line">    sessConfMap.put(JdbcConnectionParams.AUTH_PASSWD, info.getProperty(JdbcConnectionParams.AUTH_PASSWD));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结合前面的异常栈，这个 <code>info</code> 就是 <code>com.dtstack.flinkx.hive.format.HiveInputFormat#executeQuery</code> 这里的 <code>properties</code> ，这个 <code>properties</code> 是从配置文件中获取的，检查后，发现配置是 null  </p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;increColumn&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;splitPk&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;startLocation&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>这些问题大致明白了——没有获取到用户名和密码导致 HS2 连接失败。  </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/30/hive-%E8%AF%BB%E5%8F%96%E8%B6%85%E6%97%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_avatar.gif">
      <meta itemprop="name" content="FanHaiQiang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宁静致远">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 宁静致远">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/30/hive-%E8%AF%BB%E5%8F%96%E8%B6%85%E6%97%B6/" class="post-title-link" itemprop="url">hive 读取超时</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-10-30 11:25:10 / 修改时间：11:42:00" itemprop="dateCreated datePublished" datetime="2022-10-30T11:25:10+08:00">2022-10-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>业务反馈 hive 读取作业执行失败<br><img src="/2022/10/30/hive-%E8%AF%BB%E5%8F%96%E8%B6%85%E6%97%B6/image-20220707143134989_1657247857902_0.png" alt="image-20220707143134989.png"><br>查看了这些失败作业，发现有些许作业是读超时了，异常栈如下</p>
<pre><code>Caused by: java.net.SocketTimeoutException: Read timed out
at java.net.SocketInputStream.socketRead0(Native Method)
at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
at java.net.SocketInputStream.read(SocketInputStream.java:171)
at java.net.SocketInputStream.read(SocketInputStream.java:141)
at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:127)
... 30 more
</code></pre>
<p>方法<code>java.net.SocketInputStream#socketRead0</code>的定义是</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">native</span> <span class="function"><span class="keyword">int</span> <span class="title">socketRead0</span><span class="params">(FileDescriptor fd,</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len,</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="keyword">int</span> timeout)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure>
<p>其中，参数<code>timeout</code>的定义是<code>the read timeout in ms</code>。<code>timeout</code>在 141 行调用，由下面的方法传入，即<code>impl.getTimeout()</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">read</span><span class="params">(<span class="type">byte</span> b[], <span class="type">int</span> off, <span class="type">int</span> length)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  <span class="keyword">return</span> read(b, off, length, impl.getTimeout());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里<code>impl</code>是类<code>AbstractPlainSocketImpl</code>的一个实例，方法<code>getTimeout()</code>返回成员变量<code>timeout</code>，该成员在方法<code>java.net.AbstractPlainSocketImpl#setOption</code>中设置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setOption</span><span class="params">(<span class="type">int</span> opt, Object val)</span> <span class="keyword">throws</span> SocketException &#123;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  <span class="keyword">case</span> SO_TIMEOUT:</span><br><span class="line">  <span class="keyword">if</span> (val == <span class="literal">null</span> || (!(val <span class="keyword">instanceof</span> Integer)))</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SocketException</span>(<span class="string">&quot;Bad parameter for SO_TIMEOUT&quot;</span>);</span><br><span class="line">  <span class="type">int</span> <span class="variable">tmp</span> <span class="operator">=</span> ((Integer) val).intValue();</span><br><span class="line">  <span class="keyword">if</span> (tmp &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;timeout &lt; 0&quot;</span>);</span><br><span class="line">  timeout = tmp;</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个方法有 3 处调用<br><img src="/2022/10/30/hive-%E8%AF%BB%E5%8F%96%E8%B6%85%E6%97%B6/image-20220708105432620_1657264951019_0.png" alt="image-20220708105432620.png"><br>如何知道哪个调用是与 hive 有关系呢？不太好找，因为有太多的调用方了。换个思路，从 hive 入手，知道肯定会执行到这里，所以打个断点，当执行到断点时，查看调用栈，就知道执行过程了。<br><img src="/2022/10/30/hive-%E8%AF%BB%E5%8F%96%E8%B6%85%E6%97%B6/image-20220708144551916_1657264974671_0.png" alt="image-20220708144551916.png"><br>这里大致流程是<br><code>com.dtstack.flinkx.hive.format.HiveInputFormat#openInternal</code>拿到查询 SQL<code>querySql</code>并执行查询<br>查询是通过方法<code>com.dtstack.flinkx.hive.format.HiveInputFormat#executeQuery</code>实现，首先获取数据库连接<code>dbConn</code><br>数据库连接通过方法<code>com.dtstack.flinkx.rdb.inputformat.JdbcInputFormat#getConnection</code> 获取，内部有个重试，调用<code>DriverManager.getConnection()</code><br><code>DriverManager</code>内部遍历注册的 drivers ，并连接，见方法<code>java.sql.DriverManager#getConnection(java.lang.String, java.util.Properties, java.lang.Class&lt;?&gt;)</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(DriverInfo aDriver : registeredDrivers) &#123;</span><br><span class="line">  <span class="comment">// If the caller does not have permission to load the driver then</span></span><br><span class="line">  <span class="comment">// skip it.</span></span><br><span class="line">  <span class="keyword">if</span>(isDriverAllowed(aDriver.driver, callerCL)) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      println(<span class="string">&quot;    trying &quot;</span> + aDriver.driver.getClass().getName());</span><br><span class="line">      <span class="type">Connection</span> <span class="variable">con</span> <span class="operator">=</span> aDriver.driver.connect(url, info); <span class="comment">//连接</span></span><br><span class="line">      <span class="keyword">if</span> (con != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// Success!</span></span><br><span class="line">        println(<span class="string">&quot;getConnection returning &quot;</span> + aDriver.driver.getClass().getName());</span><br><span class="line">        <span class="keyword">return</span> (con);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SQLException ex) &#123;</span><br><span class="line">      <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    println(<span class="string">&quot;    skipping: &quot;</span> + aDriver.getClass().getName());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Hive 场景下，注册的 driver 是 <code>HiveDriver</code>，connect 方法中就是创建一个<code>HiveConnection</code> 对象</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Connection <span class="title function_">connect</span><span class="params">(String url, Properties info)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">  <span class="keyword">return</span> acceptsURL(url) ? <span class="keyword">new</span> <span class="title class_">HiveConnection</span>(url, info) : <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对象<code>HiveConnection</code>的构造方法如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">HiveConnection</span><span class="params">(String uri, Properties info)</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">  setupLoginTimeout(); </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    connParams = Utils.parseURL(uri);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (ZooKeeperHiveClientException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SQLException</span>(e);</span><br><span class="line">  &#125;</span><br><span class="line">  jdbcUriString = connParams.getJdbcUriString();</span><br><span class="line">  <span class="comment">// extract parsed connection parameters:</span></span><br><span class="line">  <span class="comment">// JDBC URL: jdbc:hive2://&lt;host&gt;:&lt;port&gt;/dbName;sess_var_list?hive_conf_list#hive_var_list</span></span><br><span class="line">  <span class="comment">// each list: &lt;key1&gt;=&lt;val1&gt;;&lt;key2&gt;=&lt;val2&gt; and so on</span></span><br><span class="line">  <span class="comment">// sess_var_list -&gt; sessConfMap</span></span><br><span class="line">  <span class="comment">// hive_conf_list -&gt; hiveConfMap</span></span><br><span class="line">  <span class="comment">// hive_var_list -&gt; hiveVarMap</span></span><br><span class="line">  host = connParams.getHost();</span><br><span class="line">  port = connParams.getPort();</span><br><span class="line">  sessConfMap = connParams.getSessionVars();</span><br><span class="line">  hiveConfMap = connParams.getHiveConfs();</span><br><span class="line"></span><br><span class="line">  hiveVarMap = connParams.getHiveVars();</span><br><span class="line">  <span class="keyword">for</span> (Map.Entry&lt;Object, Object&gt; kv : info.entrySet()) &#123;</span><br><span class="line">    <span class="keyword">if</span> ((kv.getKey() <span class="keyword">instanceof</span> String)) &#123;</span><br><span class="line">      <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> (String) kv.getKey();</span><br><span class="line">      <span class="keyword">if</span> (key.startsWith(HIVE_VAR_PREFIX)) &#123;</span><br><span class="line">        hiveVarMap.put(key.substring(HIVE_VAR_PREFIX.length()), info.getProperty(key));</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.startsWith(HIVE_CONF_PREFIX)) &#123;</span><br><span class="line">        hiveConfMap.put(key.substring(HIVE_CONF_PREFIX.length()), info.getProperty(key));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  isEmbeddedMode = connParams.isEmbeddedMode();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (isEmbeddedMode) &#123;</span><br><span class="line">    <span class="type">EmbeddedThriftBinaryCLIService</span> <span class="variable">embeddedClient</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">EmbeddedThriftBinaryCLIService</span>();</span><br><span class="line">    embeddedClient.init(<span class="keyword">new</span> <span class="title class_">HiveConf</span>());</span><br><span class="line">    client = embeddedClient;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// extract user/password from JDBC connection properties if its not supplied in the</span></span><br><span class="line">    <span class="comment">// connection URL</span></span><br><span class="line">    <span class="keyword">if</span> (info.containsKey(JdbcConnectionParams.AUTH_USER)) &#123;</span><br><span class="line">      sessConfMap.put(JdbcConnectionParams.AUTH_USER, info.getProperty(JdbcConnectionParams.AUTH_USER));</span><br><span class="line">      <span class="keyword">if</span> (info.containsKey(JdbcConnectionParams.AUTH_PASSWD)) &#123;</span><br><span class="line">        sessConfMap.put(JdbcConnectionParams.AUTH_PASSWD, info.getProperty(JdbcConnectionParams.AUTH_PASSWD));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (info.containsKey(JdbcConnectionParams.AUTH_TYPE)) &#123;</span><br><span class="line">      sessConfMap.put(JdbcConnectionParams.AUTH_TYPE, info.getProperty(JdbcConnectionParams.AUTH_TYPE));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// open the client transport</span></span><br><span class="line">    openTransport(); <span class="comment">// 从这里开始</span></span><br><span class="line">    <span class="comment">// set up the client</span></span><br><span class="line">    client = <span class="keyword">new</span> <span class="title class_">TCLIService</span>.Client(<span class="keyword">new</span> <span class="title class_">TBinaryProtocol</span>(transport));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// add supported protocols</span></span><br><span class="line">  supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V1);</span><br><span class="line">  supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V2);</span><br><span class="line">  supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V3);</span><br><span class="line">  supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V4);</span><br><span class="line">  supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V5);</span><br><span class="line">  supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V6);</span><br><span class="line">  supportedProtocols.add(TProtocolVersion.HIVE_CLI_SERVICE_PROTOCOL_V7);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// open client session</span></span><br><span class="line">  openSession();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Wrap the client with a thread-safe proxy to serialize the RPC calls</span></span><br><span class="line">  client = newSynchronizedClient(client);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用方法<code>setupLoginTimeout()</code>设置<code>loginTimeout</code>，内部获取的是<code>java.sql.DriverManager#loginTimeout</code>，这个变量是类的 static 成员，就是参考资料中提到的多个 JDBC driver 驱动存在时，会被覆盖导致问题<br>调用<code>org.apache.hive.jdbc.Utils#parseURL</code>解析 jdbc url 连接， <code>jdbc:hive2://&lt;host1&gt;:&lt;port1&gt;,&lt;host2&gt;:&lt;port2&gt;/dbName;sess_var_list?hive_conf_list#hive_var_list</code>，其中几个 list 是以<code>;</code>分隔的键值对，分别对应 URI 的 path、query和fragment，内部也是用 URI 类来提取的各个部分的<br>调用方法<code>org.apache.hive.jdbc.HiveConnection#openTransport</code>打开客户端连接，判断是个二进制协议还是 http 协议，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">openTransport</span><span class="params">()</span> <span class="keyword">throws</span> SQLException &#123;</span><br><span class="line">  <span class="type">int</span> <span class="variable">numRetries</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">  <span class="type">int</span> <span class="variable">maxRetries</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    maxRetries = Integer.parseInt(sessConfMap.get(JdbcConnectionParams.RETRIES));</span><br><span class="line">  &#125; <span class="keyword">catch</span>(NumberFormatException e) &#123;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      assumeSubject =</span><br><span class="line">        JdbcConnectionParams.AUTH_KERBEROS_AUTH_TYPE_FROM_SUBJECT.equals(sessConfMap</span><br><span class="line">                                                                         .get(JdbcConnectionParams.AUTH_KERBEROS_AUTH_TYPE));</span><br><span class="line">      transport = isHttpTransportMode() ? createHttpTransport() : createBinaryTransport(); <span class="comment">//判断是个二进制协议还是 http 协议，</span></span><br><span class="line">      <span class="keyword">if</span> (!transport.isOpen()) &#123;</span><br><span class="line">        transport.open();</span><br><span class="line">      &#125;</span><br><span class="line">      logZkDiscoveryMessage(<span class="string">&quot;Connected to &quot;</span> + connParams.getHost() + <span class="string">&quot;:&quot;</span> + connParams.getPort());</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (TTransportException e) &#123;</span><br><span class="line">      <span class="comment">// We&#x27;ll retry till we exhaust all HiveServer2 nodes from ZooKeeper</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里是二进制，调用方法<code>org.apache.hive.jdbc.HiveConnection#createBinaryTransport</code>，内部调用<code>org.apache.hive.jdbc.HiveConnection#createUnderlyingTransport</code>创建底层的 transport</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> TTransport <span class="title function_">createUnderlyingTransport</span><span class="params">()</span> <span class="keyword">throws</span> TTransportException &#123;</span><br><span class="line">  <span class="type">TTransport</span> <span class="variable">transport</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">  <span class="comment">// Note: Thrift returns an SSL socket that is already bound to the specified host:port</span></span><br><span class="line">  <span class="comment">// Therefore an open called on this would be a no-op later</span></span><br><span class="line">  <span class="comment">// Hence, any TTransportException related to connecting with the peer are thrown here.</span></span><br><span class="line">  <span class="comment">// Bubbling them up the call hierarchy so that a retry can happen in openTransport,</span></span><br><span class="line">  <span class="comment">// if dynamic service discovery is configured.</span></span><br><span class="line">  <span class="keyword">if</span> (isSslConnection()) &#123;</span><br><span class="line">    <span class="comment">// get SSL socket</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// get non-SSL socket transport</span></span><br><span class="line">    transport = HiveAuthUtils.getSocketTransport(host, port, loginTimeout);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> transport;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里获取 transport 的时候，传了<code>loginTimeout</code><br>方法<code>org.apache.hadoop.hive.common.auth.HiveAuthUtils#getSocketTransport</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> TTransport <span class="title function_">getSocketTransport</span><span class="params">(String host, <span class="type">int</span> port, <span class="type">int</span> loginTimeout)</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">TSocket</span>(host, port, loginTimeout);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>继续看 <code>TSocket</code> 的初始化</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">TSocket</span><span class="params">(String host, <span class="type">int</span> port, <span class="type">int</span> timeout)</span> &#123;</span><br><span class="line">  <span class="built_in">this</span>.socket_ = <span class="literal">null</span>;</span><br><span class="line">  <span class="built_in">this</span>.host_ = <span class="literal">null</span>;</span><br><span class="line">  <span class="built_in">this</span>.port_ = <span class="number">0</span>;</span><br><span class="line">  <span class="built_in">this</span>.timeout_ = <span class="number">0</span>;</span><br><span class="line">  <span class="built_in">this</span>.host_ = host;</span><br><span class="line">  <span class="built_in">this</span>.port_ = port;</span><br><span class="line">  <span class="built_in">this</span>.timeout_ = timeout;</span><br><span class="line">  <span class="built_in">this</span>.initSocket(); <span class="comment">//</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">initSocket</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="built_in">this</span>.socket_ = <span class="keyword">new</span> <span class="title class_">Socket</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.socket_.setSoLinger(<span class="literal">false</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">this</span>.socket_.setTcpNoDelay(<span class="literal">true</span>);</span><br><span class="line">    <span class="built_in">this</span>.socket_.setKeepAlive(<span class="literal">true</span>);</span><br><span class="line">    <span class="built_in">this</span>.socket_.setSoTimeout(<span class="built_in">this</span>.timeout_); <span class="comment">//</span></span><br><span class="line">  &#125; <span class="keyword">catch</span> (SocketException var2) &#123;</span><br><span class="line">    LOGGER.error(<span class="string">&quot;Could not configure socket.&quot;</span>, var2);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>java.net.Socket#setSoTimeout</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">setSoTimeout</span><span class="params">(<span class="type">int</span> timeout)</span> <span class="keyword">throws</span> SocketException &#123;</span><br><span class="line">  <span class="keyword">if</span> (isClosed())</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SocketException</span>(<span class="string">&quot;Socket is closed&quot;</span>);</span><br><span class="line">  <span class="keyword">if</span> (timeout &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(<span class="string">&quot;timeout can&#x27;t be negative&quot;</span>);</span><br><span class="line"></span><br><span class="line">  getImpl().setOption(SocketOptions.SO_TIMEOUT, <span class="keyword">new</span> <span class="title class_">Integer</span>(timeout)); <span class="comment">//</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里设置的是 socket 的读取超时，实际上 timeout_，也用于 socket 连接超时<br>最后看下，<code>java.sql.DriverManager#loginTimeout</code>是如何设置的，类似的，添加断点，发现是在方法<code>com.dtstack.flinkx.util.ClassUtil#forName(java.lang.String, java.lang.ClassLoader)</code>中设置，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">forName</span><span class="params">(String clazz, ClassLoader classLoader)</span>  &#123;</span><br><span class="line">  <span class="keyword">synchronized</span> (LOCK_STR)&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      Class.forName(clazz, <span class="literal">true</span>, classLoader);</span><br><span class="line">      DriverManager.setLoginTimeout(<span class="number">10</span>); <span class="comment">//10s</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2022/10/30/hive-%E8%AF%BB%E5%8F%96%E8%B6%85%E6%97%B6/image-20220708110105135_1657265225155_0.png" alt="image-20220708110105135.png"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/30/PG-%E8%AF%BB%E5%8F%96%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%9B%A0%E4%B8%B4%E6%97%B6%E7%A9%BA%E9%97%B4%E4%B8%8D%E8%B6%B3%E5%AF%BC%E8%87%B4%E4%BB%BB%E5%8A%A1%E5%A4%B1%E8%B4%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_avatar.gif">
      <meta itemprop="name" content="FanHaiQiang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="宁静致远">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 宁静致远">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/30/PG-%E8%AF%BB%E5%8F%96%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%9B%A0%E4%B8%B4%E6%97%B6%E7%A9%BA%E9%97%B4%E4%B8%8D%E8%B6%B3%E5%AF%BC%E8%87%B4%E4%BB%BB%E5%8A%A1%E5%A4%B1%E8%B4%A5/" class="post-title-link" itemprop="url">PG 读取大量数据因临时空间不足导致任务失败</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-10-30 10:43:10 / 修改时间：10:58:02" itemprop="dateCreated datePublished" datetime="2022-10-30T10:43:10+08:00">2022-10-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>业务方有一个同步 PG 的作业，数据量级大致是 1.5+ 亿条。任务执行失败，报错</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2022</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">14</span>:<span class="number">31</span>:<span class="number">37.178</span> <span class="selector-attr">[flink-akka.actor.default-dispatcher-21]</span> INFO  org<span class="selector-class">.apache</span><span class="selector-class">.flink</span><span class="selector-class">.runtime</span><span class="selector-class">.executiongraph</span><span class="selector-class">.ExecutionGraph</span>  - Source: postgresqlreader (<span class="number">1</span>/<span class="number">1</span>) (<span class="number">77</span>bd8cb9299189456dceee9609b5d03a) switched from RUNNING to FAILED on org<span class="selector-class">.apache</span><span class="selector-class">.flink</span><span class="selector-class">.runtime</span><span class="selector-class">.jobmaster</span><span class="selector-class">.slotpool</span>.SingleLogicalSlot@<span class="number">55</span>bedd88.</span><br><span class="line">java<span class="selector-class">.lang</span><span class="selector-class">.IllegalArgumentException</span>: <span class="built_in">open</span>() failed<span class="selector-class">.ERROR</span>: temporary file size exceeds temp_file_limit (<span class="number">15728640</span>kB)</span><br><span class="line">	at com<span class="selector-class">.dtstack</span><span class="selector-class">.flinkx</span><span class="selector-class">.rdb</span><span class="selector-class">.inputformat</span><span class="selector-class">.JdbcInputFormat</span><span class="selector-class">.openInternal</span>(JdbcInputFormat<span class="selector-class">.java</span>:<span class="number">154</span>)</span><br><span class="line">	at com<span class="selector-class">.dtstack</span><span class="selector-class">.flinkx</span><span class="selector-class">.inputformat</span><span class="selector-class">.BaseRichInputFormat</span><span class="selector-class">.open</span>(BaseRichInputFormat<span class="selector-class">.java</span>:<span class="number">183</span>)</span><br><span class="line">	at com<span class="selector-class">.dtstack</span><span class="selector-class">.flinkx</span><span class="selector-class">.streaming</span><span class="selector-class">.api</span><span class="selector-class">.functions</span><span class="selector-class">.source</span><span class="selector-class">.DtInputFormatSourceFunction</span><span class="selector-class">.run</span>(DtInputFormatSourceFunction<span class="selector-class">.java</span>:<span class="number">124</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flink</span><span class="selector-class">.streaming</span><span class="selector-class">.api</span><span class="selector-class">.operators</span><span class="selector-class">.StreamSource</span><span class="selector-class">.run</span>(StreamSource<span class="selector-class">.java</span>:<span class="number">100</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flink</span><span class="selector-class">.streaming</span><span class="selector-class">.api</span><span class="selector-class">.operators</span><span class="selector-class">.StreamSource</span><span class="selector-class">.run</span>(StreamSource<span class="selector-class">.java</span>:<span class="number">63</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flink</span><span class="selector-class">.streaming</span><span class="selector-class">.runtime</span><span class="selector-class">.tasks</span>.SourceStreamTask<span class="variable">$LegacySourceFunctionThread</span><span class="selector-class">.run</span>(SourceStreamTask<span class="selector-class">.java</span>:<span class="number">201</span>)</span><br><span class="line">Caused by: org<span class="selector-class">.postgresql</span><span class="selector-class">.util</span><span class="selector-class">.PSQLException</span>: ERROR: temporary file size exceeds temp_file_limit (<span class="number">15728640</span>kB)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.core</span><span class="selector-class">.v3</span><span class="selector-class">.QueryExecutorImpl</span><span class="selector-class">.receiveErrorResponse</span>(QueryExecutorImpl<span class="selector-class">.java</span>:<span class="number">2433</span>)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.core</span><span class="selector-class">.v3</span><span class="selector-class">.QueryExecutorImpl</span><span class="selector-class">.processResults</span>(QueryExecutorImpl<span class="selector-class">.java</span>:<span class="number">2178</span>)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.core</span><span class="selector-class">.v3</span><span class="selector-class">.QueryExecutorImpl</span><span class="selector-class">.execute</span>(QueryExecutorImpl<span class="selector-class">.java</span>:<span class="number">306</span>)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.jdbc</span><span class="selector-class">.PgStatement</span><span class="selector-class">.executeInternal</span>(PgStatement<span class="selector-class">.java</span>:<span class="number">441</span>)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.jdbc</span><span class="selector-class">.PgStatement</span><span class="selector-class">.execute</span>(PgStatement<span class="selector-class">.java</span>:<span class="number">365</span>)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.jdbc</span><span class="selector-class">.PgStatement</span><span class="selector-class">.executeWithFlags</span>(PgStatement<span class="selector-class">.java</span>:<span class="number">307</span>)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.jdbc</span><span class="selector-class">.PgStatement</span><span class="selector-class">.executeCachedSql</span>(PgStatement<span class="selector-class">.java</span>:<span class="number">293</span>)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.jdbc</span><span class="selector-class">.PgStatement</span><span class="selector-class">.executeWithFlags</span>(PgStatement<span class="selector-class">.java</span>:<span class="number">270</span>)</span><br><span class="line">	at org<span class="selector-class">.postgresql</span><span class="selector-class">.jdbc</span><span class="selector-class">.PgStatement</span><span class="selector-class">.executeQuery</span>(PgStatement<span class="selector-class">.java</span>:<span class="number">224</span>)</span><br><span class="line">	at com<span class="selector-class">.dtstack</span><span class="selector-class">.flinkx</span><span class="selector-class">.rdb</span><span class="selector-class">.inputformat</span><span class="selector-class">.JdbcInputFormat</span><span class="selector-class">.executeQuery</span>(JdbcInputFormat<span class="selector-class">.java</span>:<span class="number">868</span>)</span><br><span class="line">	at com<span class="selector-class">.dtstack</span><span class="selector-class">.flinkx</span><span class="selector-class">.rdb</span><span class="selector-class">.inputformat</span><span class="selector-class">.JdbcInputFormat</span><span class="selector-class">.openInternal</span>(JdbcInputFormat<span class="selector-class">.java</span>:<span class="number">149</span>)</span><br><span class="line">	... <span class="number">5</span> common frames omitted</span><br></pre></td></tr></table></figure>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>这看起来就是 PG 数据库的问题，需要增加配置<code>temp_file_limit</code>。不过业务说 1.0 上可以执行，不放心用 2.0 的配置在 1.0 上手动提交了一个作业，居然可以。<br>从 2.0 的执行日志中获取了执行的 SQL</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> &quot;ts&quot;,&quot;asm_name&quot;,&quot;sequence&quot;,&quot;process_name&quot;,&quot;thread_name&quot;,&quot;pid&quot;,&quot;tid&quot;,&quot;energy_raw&quot;,&quot;uniform_time_ms&quot;,&quot;curr_time&quot; <span class="keyword">FROM</span> &quot;ctp_metrics27&quot; <span class="keyword">WHERE</span> <span class="number">1</span><span class="operator">=</span><span class="number">1</span>   <span class="keyword">and</span> &quot;curr_time&quot; <span class="operator">&gt;=</span> <span class="string">&#x27;2022-10-27 00:00:00.000000&#x27;</span> <span class="keyword">and</span> &quot;curr_time&quot; <span class="operator">&lt;</span> <span class="string">&#x27;2022-10-28 00:00:00.000000&#x27;</span> <span class="keyword">order</span> <span class="keyword">by</span> curr_time</span><br></pre></td></tr></table></figure>
<p>注意到，这个 sql 的最后多了 <code>order by</code>，这是个多余的操作，而且为了做排序，必定会使用到临时空间，考虑到数据量级，空间不足就是理应会发生的了。<br>看看这个 <code>order by</code> 是在哪里添加的——<br>flinkx 中同步关系型数据库的逻辑，简单的概括就是<code>InputFormat</code>的<code>open</code>方法中创建一个数据库连接，执行 SQL，得到结果集，其中执行的 SQL 的生成分成两步</p>
<ol>
<li>在调用方法<code>com.dtstack.flinkx.rdb.datareader.JdbcDataReader#readData</code>处理配置时，调用<code>com.dtstack.flinkx.rdb.datareader.QuerySqlBuilder#buildSql</code>生成一个 SQL 模板，其中包含了增量&#x2F;恢复、切分条件的占位符</li>
<li>在调用方法<code>com.dtstack.flinkx.rdb.inputformat.JdbcInputFormat#openInternal</code>打开数据库时，调用<code>com.dtstack.flinkx.rdb.inputformat.JdbcInputFormat#buildQuerySql</code>将模板中的占位符替换掉，得到最终的 SQL</li>
</ol>
<p>PG 特殊的地方在于它将父类的方法<code>com.dtstack.flinkx.postgresql.reader.PostgresqlQuerySqlBuilder#buildQuerySql</code>给覆盖掉了，覆盖后的方法与父类的差异多了一行</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> String <span class="title function_">buildQuerySql</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  sb.append(buildOrderSql()); <span class="comment">// 多了这一行</span></span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//com.dtstack.flinkx.rdb.datareader.QuerySqlBuilder#buildOrderSql</span></span><br><span class="line"><span class="keyword">protected</span> String <span class="title function_">buildOrderSql</span><span class="params">()</span>&#123;</span><br><span class="line">  String column;</span><br><span class="line">  <span class="keyword">if</span>(isIncrement)&#123;</span><br><span class="line">    column = incrementColumn;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span>(isRestore)&#123;</span><br><span class="line">    column = restoreColumn;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    column = orderByColumn;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> StringUtils.isEmpty(column) ? <span class="string">&quot;&quot;</span> : String.format(<span class="string">&quot; order by %s&quot;</span>, column);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，当任务是增量任务时，会添加<code>order by 增量字段</code>。</p>
<h2 id="处理"><a href="#处理" class="headerlink" title="处理"></a>处理</h2><p>这段逻辑是没有必要的，去掉即可。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">FanHaiQiang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.1.7/mermaid.min.js","integrity":"sha256-G58AID1YoX5YaEtWfXSI0VLrZ6N4kvNvwg0BI8zUFxE="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  





</body>
</html>
